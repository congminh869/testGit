{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 - Prediction (RUL) using Multivariate LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Embedding\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Train and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data \n",
    "train_df = pd.read_csv('data/train_01.txt', sep=\" \", header=None)\n",
    "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test_df = pd.read_csv('data/test_01.txt', sep=\" \", header=None)\n",
    "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ground truth data\n",
    "truth_df = pd.read_csv('data/truth_01.txt', sep=\" \", header=None)\n",
    "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(['id','cycle'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate True Values for Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Labeling - generate column RUL\n",
    "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "train_df = train_df.merge(rul, on=['id'], how='left')\n",
    "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
    "train_df.drop('max', axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate label columns for training data\n",
    "w1 = 30\n",
    "w0 = 15\n",
    "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
    "train_df['label2'] = train_df['label1']\n",
    "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax normalization\n",
    "train_df['cycle_norm'] = train_df['cycle']\n",
    "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=train_df.index)\n",
    "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "train_df = join_df.reindex(columns = train_df.columns)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['cycle_norm'] = test_df['cycle']\n",
    "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
    "                            columns=cols_normalize, \n",
    "                            index=test_df.index)\n",
    "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "test_df = test_join_df.reindex(columns = test_df.columns)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate True Values for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column max for test data\n",
    "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "truth_df.columns = ['more']\n",
    "truth_df['id'] = truth_df.index + 1\n",
    "truth_df['max'] = rul['max'] + truth_df['more']\n",
    "truth_df.drop('more', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate RUL for test data\n",
    "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
    "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
    "test_df.drop('max', axis=1, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate label columns w0 and w1 for test data\n",
    "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
    "test_df['label2'] = test_df['label1']\n",
    "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 120 cycles\n",
    "sequence_length = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for visualizations \n",
    "# window of 120 cycles prior to a failure point for engine id 8\n",
    "engine_id8 = test_df[test_df['id'] == 8]\n",
    "engine_id8_120cycleWindow = engine_id8[engine_id8['RUL'] <= engine_id8['RUL'].min() + 120]\n",
    "cols1 = ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10']\n",
    "engine_id8_120cycleWindow1 = engine_id8_120cycleWindow[cols1]\n",
    "cols2 = ['s11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "engine_id8_120cycleWindow2 = engine_id8_120cycleWindow[cols2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting sensor data for engine ID 8 prior to a failure point - sensors 1-10 \n",
    "ax1 = engine_id8_120cycleWindow1.plot(subplots=True, sharex=True, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting sensor data for engine ID 8 prior to a failure point - sensors 11-21 \n",
    "ax2 = engine_id8_120cycleWindow2.plot(subplots=True, sharex=True, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "# sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "# sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "sensor_cols = ['s2', 's3', 's4', 's7', 's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', 's20', 's21']\n",
    "sequence_cols = ['setting1', 'setting2', 'cycle_norm']\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n",
    "           for id in train_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels\n",
    "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL']) \n",
    "             for id in train_df['id'].unique()]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Input, Reshape, Dropout\n",
    "from keras import Model\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "results = {}\n",
    "for num_cells in [30, 40, 50,60,70,80,90,100]:\n",
    "    for dropout_rate in [0, 0.1, 0.2,0.3,0.4]:\n",
    "        for lr in [1e-4, 1e-3, 1e-2]:\n",
    "            print('Running with', num_cells, \n",
    "                  'LSTM cells, dropout =', dropout_rate, \n",
    "                  'and learning rate =', lr, '...')\n",
    "\n",
    "            # build network\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(\n",
    "                units=num_cells,\n",
    "                return_sequences=True,\n",
    "                input_shape=(sequence_length, nb_features)))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(LSTM(\n",
    "                units=num_cells,\n",
    "                return_sequences=False))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(units=1, activation='relu'))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            optimiser = RMSprop(lr=lr)\n",
    "            model.compile(loss=\"mse\", optimizer=optimiser, metrics=['mse'])\n",
    "\n",
    "            # fit network for a maximum of 200 epochs with early stopping (patience=10)\n",
    "            history = model.fit(seq_array, label_array, epochs=40, batch_size=200, validation_split=0.05, verbose=1,\n",
    "                             callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')])\n",
    "            \n",
    "\n",
    "            # get training and validation loss at best epoch (number of epochs - patience)\n",
    "            num_epochs = len(history.history['val_loss'])\n",
    "            best_epoch = num_epochs - 10\n",
    "            train_mse = history.history['loss'][best_epoch]\n",
    "            val_mse = history.history['val_loss'][best_epoch] \n",
    "            results[(num_cells, dropout_rate, lr, best_epoch)] = {'train_mse': train_mse, \n",
    "                                                                  'val_mse': val_mse}                                                                                          \n",
    "            print('Train MSE =', train_mse, ', Validation MSE =', val_mse)        \n",
    "            print('+----------------------------------------------------------------------+')\n",
    "\n",
    "val_results = {key: results[key]['val_mse'] for key in results.keys()}\n",
    "num_cells, dropout_rate, lr, num_epochs = min(val_results, key=val_results.get)\n",
    "print('Best parameters:', num_cells, \n",
    "        'LSTM cells, training for', num_epochs, \n",
    "        'epochs with dropout =', dropout_rate, \n",
    "        'and learning rate =', lr)\n",
    "\n",
    "#Best parameters: num_cells=50, dropout_rate=0.1, lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells=50\n",
    "dropout_rate=0.1\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Input, Reshape, Dropout\n",
    "from keras import Model\n",
    "\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "         units=num_cells,\n",
    "         return_sequences=True,\n",
    "         input_shape=(sequence_length, nb_features)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(\n",
    "          units=num_cells,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(lr))\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "model.add(Activation(\"relu\"))\n",
    "optimiser = RMSprop(lr=lr)\n",
    "model.compile(loss=\"mse\", optimizer=optimiser, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit the network\n",
    "hist = model.fit(seq_array, label_array, epochs=40, batch_size=200, validation_split=0.05, verbose=1,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(hist.history['mse'])\n",
    "plt.plot(hist.history['val_mse'])\n",
    "plt.title('MSE')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('# Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('Epoch.png', dpi=1200) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training metrics\n",
    "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
    "print('MSE: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n",
    "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
    "\n",
    "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
    "seq_array_test_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array_test_last = test_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
    "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
    "label_array_test_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_array_test_last.shape)\n",
    "print(label_array_test_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test metrics\n",
    "scores_test = model.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
    "print('MSE: {}'.format(scores_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([[scores_test[1]],],\n",
    "                         columns = ['MSE'],\n",
    "                         index = ['LSTM'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Predictions vs True RUL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(seq_array_test_last, verbose=0)\n",
    "\n",
    "import matplotlib.pyplot as plt2\n",
    "%matplotlib inline\n",
    "plt2.figure()\n",
    "\n",
    "plt2.plot(y_pred_test, color='red', label='Prediction')\n",
    "plt2.plot(label_array_test_last, color='blue', label='Ground Truth')\n",
    "plt2.xlabel('Machine ID')\n",
    "plt2.ylabel('Remaining Useful Lifetime')\n",
    "plt2.legend(loc='upper left')\n",
    "\n",
    "plt2.savefig('plot.png', dpi=1200) \n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
